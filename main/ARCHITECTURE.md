# System Architecture

## ğŸ—ï¸ Two-Server Architecture

Your system runs **TWO separate servers** that work together:

### Server 1: Backend (FastAPI) - Port 8000
**Purpose:** Main processing engine
**Technology:** Python + FastAPI
**Location:** `unified/main/backend/`

### Server 2: Frontend (Vite) - Port 5173
**Purpose:** User interface
**Technology:** React + Vite + TailwindCSS
**Location:** `unified/main/frontend/`

---

## ğŸ”„ Request Flow

### Upload Document Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER ACTION                                              â”‚
â”‚    User drags PDF to browser (localhost:5173)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND (React - Port 5173)                            â”‚
â”‚    â€¢ UploadPage.jsx captures file                          â”‚
â”‚    â€¢ Calls api.uploadDocument(file)                        â”‚
â”‚    â€¢ Sends: POST /upload with FormData                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Vite Proxy
                         â”‚ /upload â†’ http://localhost:8000/upload
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BACKEND (FastAPI - Port 8000)                           â”‚
â”‚    routes/upload.py receives request                       â”‚
â”‚                                                             â”‚
â”‚    Step 1: Validate file (PDF/JPG/PNG, size)               â”‚
â”‚    Step 2: Run OCR                                          â”‚
â”‚            â”œâ”€ Tesseract (local) OR                         â”‚
â”‚            â””â”€ Sarvam AI (cloud)                            â”‚
â”‚    Step 3: Validate OCR result                             â”‚
â”‚            â””â”€ validation_agent.py                          â”‚
â”‚    Step 4: Preprocess text                                 â”‚
â”‚            â”œâ”€ pp1: Cleaning                                â”‚
â”‚            â”œâ”€ pp2: Normalization                           â”‚
â”‚            â”œâ”€ pp3: Metadata (SpaCy NER)                    â”‚
â”‚            â””â”€ pp4: Chunking                                â”‚
â”‚    Step 5: Generate embeddings                             â”‚
â”‚            â””â”€ SentenceTransformer (384-dim)                â”‚
â”‚    Step 6: Store in FAISS vector DB                        â”‚
â”‚    Step 7: Save JSON to data/extracted_json/               â”‚
â”‚                                                             â”‚
â”‚    Returns: JSON with results                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ JSON Response
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FRONTEND DISPLAYS RESULTS                                â”‚
â”‚    â€¢ OCRResultCard shows confidence, pages, words           â”‚
â”‚    â€¢ ValidationBadge shows Ready/Review/Rejected            â”‚
â”‚    â€¢ StructuredFields shows extracted data                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chat Query Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER ACTION                                              â”‚
â”‚    User types question in chat (localhost:5173)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND (React - Port 5173)                            â”‚
â”‚    â€¢ ChatPage.jsx captures query                           â”‚
â”‚    â€¢ Calls api.sendChat(query)                             â”‚
â”‚    â€¢ Sends: POST /chat with JSON body                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Vite Proxy
                         â”‚ /chat â†’ http://localhost:8000/chat
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BACKEND (FastAPI - Port 8000)                           â”‚
â”‚    routes/chat.py receives request                         â”‚
â”‚                                                             â”‚
â”‚    Step 1: Refine query with LLM                           â”‚
â”‚            â””â”€ rag_agent.refine_query()                     â”‚
â”‚            â””â”€ Llama 3.1 8B makes query more specific       â”‚
â”‚                                                             â”‚
â”‚    Step 2: Retrieve relevant chunks                        â”‚
â”‚            â”œâ”€ Encode query with SentenceTransformer        â”‚
â”‚            â”œâ”€ Search FAISS index (cosine similarity)       â”‚
â”‚            â””â”€ Filter by threshold (0.3)                    â”‚
â”‚                                                             â”‚
â”‚    Step 3: Generate answer with LLM                        â”‚
â”‚            â””â”€ rag_agent.generate_answer()                  â”‚
â”‚            â””â”€ Llama 3.1 8B generates answer from context   â”‚
â”‚                                                             â”‚
â”‚    Returns: JSON with answer + sources                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ JSON Response
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FRONTEND DISPLAYS RESULTS                                â”‚
â”‚    â€¢ MessageBubble shows answer                             â”‚
â”‚    â€¢ SourcePanel shows retrieved chunks with similarity     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Port Configuration

### Backend: Port 8000
```bash
# Configured in: unified/main/.env
PORT=8000
HOST=0.0.0.0

# Accessible at:
http://localhost:8000          # Root info
http://localhost:8000/docs     # Swagger UI
http://localhost:8000/health   # Health check
http://localhost:8000/upload   # Upload endpoint
http://localhost:8000/chat     # Chat endpoint
```

### Frontend: Port 5173
```bash
# Configured in: unified/main/frontend/vite.config.js
# Default Vite dev server port

# Accessible at:
http://localhost:5173          # Main UI
http://localhost:5173/         # Upload page
http://localhost:5173/chat     # Chat page
```

### Proxy Configuration
The frontend proxies API requests to the backend:

```javascript
// vite.config.js
export default defineConfig({
  server: {
    proxy: {
      '/upload': 'http://localhost:8000',
      '/chat': 'http://localhost:8000',
      '/health': 'http://localhost:8000'
    }
  }
})
```

**What this means:**
- When frontend calls `/upload`, Vite forwards to `http://localhost:8000/upload`
- User only sees `http://localhost:5173` in browser
- No CORS issues because proxy handles it

---

## ğŸ“¦ Component Breakdown

### Backend Components

```
backend/
â”œâ”€â”€ main.py                    # FastAPI app entry point
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py             # Settings from .env
â”‚   â””â”€â”€ logging.py            # Logging setup
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ upload.py             # POST /upload endpoint
â”‚   â”œâ”€â”€ chat.py               # POST /chat endpoint
â”‚   â””â”€â”€ health.py             # GET /health endpoint
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ocr_service.py        # OCR engine selector
â”‚   â”œâ”€â”€ embedding_service.py  # SentenceTransformer
â”‚   â”œâ”€â”€ llm_service.py        # Llama 3.1 8B
â”‚   â”œâ”€â”€ retrieval_service.py  # FAISS search
â”‚   â”œâ”€â”€ rag_service.py        # Full RAG pipeline
â”‚   â”œâ”€â”€ vector_store.py       # FAISS wrapper
â”‚   â””â”€â”€ preprocessing/
â”‚       â”œâ”€â”€ pp1_cleaning.py   # Text cleaning
â”‚       â”œâ”€â”€ pp2_normalization.py  # Normalization
â”‚       â”œâ”€â”€ pp3_metadata.py   # SpaCy NER
â”‚       â””â”€â”€ pp4_chunking.py   # Text chunking
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ validation_agent.py   # OCR quality check
â”‚   â””â”€â”€ rag_agent.py          # LLM wrapper
â””â”€â”€ vector_db/
    â””â”€â”€ db_client.py          # FAISS client
```

### Frontend Components

```
frontend/
â”œâ”€â”€ index.html                # Entry HTML
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.jsx             # React entry point
â”‚   â”œâ”€â”€ App.jsx              # Router setup
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.js           # API client (axios)
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Layout.jsx       # Header + nav + footer
â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.jsx        # Upload interface
â”‚   â”‚   â”‚   â”œâ”€â”€ OCRResultCard.jsx     # OCR results
â”‚   â”‚   â”‚   â”œâ”€â”€ ValidationBadge.jsx   # Validation status
â”‚   â”‚   â”‚   â””â”€â”€ StructuredFields.jsx  # Extracted fields
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”œâ”€â”€ ChatPage.jsx          # Chat interface
â”‚   â”‚       â”œâ”€â”€ MessageBubble.jsx     # Message display
â”‚   â”‚       â””â”€â”€ SourcePanel.jsx       # Retrieved sources
â”‚   â””â”€â”€ index.css            # TailwindCSS
â””â”€â”€ vite.config.js           # Vite + proxy config
```

---

## ğŸš€ Starting the System

### Option 1: Two Terminals (Recommended)

**Terminal 1 - Backend:**
```bash
cd unified/main/backend
source venv/bin/activate
python main.py
```
Output: `INFO: Uvicorn running on http://0.0.0.0:8000`

**Terminal 2 - Frontend:**
```bash
cd unified/main/frontend
npm run dev
```
Output: `Local: http://localhost:5173/`

### Option 2: Background Processes

**Start Backend in Background:**
```bash
cd unified/main/backend
source venv/bin/activate
nohup python main.py > backend.log 2>&1 &
```

**Start Frontend in Background:**
```bash
cd unified/main/frontend
nohup npm run dev > frontend.log 2>&1 &
```

**Stop Processes:**
```bash
# Find and kill processes
lsof -ti:8000 | xargs kill -9  # Backend
lsof -ti:5173 | xargs kill -9  # Frontend
```

---

## ğŸ” Debugging

### Check if Backend is Running
```bash
curl http://localhost:8000/health
# Should return JSON with status
```

### Check if Frontend is Running
```bash
curl http://localhost:5173
# Should return HTML
```

### View Backend Logs
```bash
tail -f unified/main/data/logs/app.log
```

### View Frontend Logs
Check browser console (F12)

### Test API Directly
```bash
# Upload test
curl -X POST http://localhost:8000/upload \
  -F "file=@test.pdf"

# Chat test
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "What is this document about?"}'
```

---

## ğŸŒ Network Flow

```
User Browser
    â”‚
    â”‚ Opens http://localhost:5173
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vite Dev Server        â”‚
â”‚  Port 5173              â”‚
â”‚  Serves React App       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ User clicks Upload/Chat
            â”‚ Frontend makes API call
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vite Proxy             â”‚
â”‚  Forwards /upload,      â”‚
â”‚  /chat, /health to      â”‚
â”‚  http://localhost:8000  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server         â”‚
â”‚  Port 8000              â”‚
â”‚  Processes Request      â”‚
â”‚  Returns JSON           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ Data Flow

### Upload Data Flow
```
PDF File (User)
    â†“
Frontend (FormData)
    â†“
Backend /upload
    â†“
OCR Engine (Text Extraction)
    â†“
Preprocessing (Cleaning, Chunking)
    â†“
Embedding Model (Vectors)
    â†“
FAISS Index (Storage)
    â†“
JSON File (data/extracted_json/)
```

### Query Data Flow
```
User Question (Text)
    â†“
Frontend (JSON)
    â†“
Backend /chat
    â†“
LLM (Query Refinement)
    â†“
Embedding Model (Query Vector)
    â†“
FAISS Index (Similarity Search)
    â†“
LLM (Answer Generation)
    â†“
Frontend (Display Answer + Sources)
```

---

## ğŸ¯ Summary

**Backend (Port 8000):**
- Main processing server
- Handles OCR, embeddings, LLM, vector DB
- Python + FastAPI
- Heavy lifting happens here

**Frontend (Port 5173):**
- User interface
- Displays results
- React + Vite
- Lightweight, just UI

**Communication:**
- Frontend â†’ Backend via HTTP requests
- Vite proxy handles routing
- JSON for data exchange

**You access:** `http://localhost:5173` (frontend)
**Frontend talks to:** `http://localhost:8000` (backend)
**User never sees:** Port 8000 (proxied)
